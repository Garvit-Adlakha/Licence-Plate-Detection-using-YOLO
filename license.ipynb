{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xml.etree.ElementTree as ET\n",
    "import torch\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.is_available() = True\n",
      "torch.cuda.device_count() = 1\n"
     ]
    }
   ],
   "source": [
    "print(f'{torch.cuda.is_available() = }')\n",
    "print(f'{torch.cuda.device_count() = }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path=r\"data\\images\\google_images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict = dict(\n",
    "   img_path=[],  \n",
    "    xmin=[], \n",
    "    xmax=[], \n",
    "    ymin=[], \n",
    "    ymax=[], \n",
    "    img_w=[], \n",
    "    img_h=[],\n",
    "    name=[]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_files = glob(f'{dataset_path}/*.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               img_path  xmin  xmax  ymin  \\\n",
      "0     data\\images\\google_images\\0073797c-a755-4972-b...   140   339   210   \n",
      "1     data\\images\\google_images\\00b42b2c-f193-4863-b...   184   292   572   \n",
      "2     data\\images\\google_images\\018b52e6-e9a1-42c2-8...   327   399   202   \n",
      "3     data\\images\\google_images\\03273806-bb1e-48da-8...   185   374   290   \n",
      "4     data\\images\\google_images\\0369b20e-b432-4409-9...   335   453   313   \n",
      "...                                                 ...   ...   ...   ...   \n",
      "1684                  data\\images\\google_images\\WB4.jpg   119   191   268   \n",
      "1685                  data\\images\\google_images\\WB5.jpg   105   187   256   \n",
      "1686                  data\\images\\google_images\\WB6.jpg   108   181   247   \n",
      "1687                  data\\images\\google_images\\WB8.jpg    98   184   210   \n",
      "1688                  data\\images\\google_images\\WB9.jpg    92   152   204   \n",
      "\n",
      "      ymax  img_w  img_h        name  \n",
      "0      260    500    335    KA19TR02  \n",
      "1      648   1280    853  TN21AT0492  \n",
      "2      227    660    280  RJ27TC0530  \n",
      "3      339    588    476  MH20CS9817  \n",
      "4      347    480    480  KL05AK3300  \n",
      "...    ...    ...    ...         ...  \n",
      "1684   292    272    363   WB02X8795  \n",
      "1685   280    272    363   WB06G4120  \n",
      "1686   266    272    363  WB02AH4655  \n",
      "1687   229    272    272   WB06J4432  \n",
      "1688   221    272    366  WB02AA5580  \n",
      "\n",
      "[1689 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "for filename in xml_files:\n",
    "    try:\n",
    "        # Parse the XML file\n",
    "        info = ET.parse(filename)\n",
    "        root = info.getroot()\n",
    "        \n",
    "        # Extract the image filename and construct the full path\n",
    "        img_name = root.find('filename').text\n",
    "        img_path = os.path.join(dataset_path, img_name)  # Use <path> for full path if available\n",
    "        \n",
    "        # Extract image dimensions from <size>\n",
    "        size_info = root.find('size')\n",
    "        img_w = int(size_info.find('width').text)\n",
    "        img_h = int(size_info.find('height').text)\n",
    "        \n",
    "        # Check if there are any <object> elements\n",
    "        objects_found = False\n",
    "        for member_object in root.findall('object'):\n",
    "            objects_found = True\n",
    "            labels_info = member_object.find('bndbox')\n",
    "            xmin = int(labels_info.find('xmin').text)\n",
    "            ymin = int(labels_info.find('ymin').text)\n",
    "            xmax = int(labels_info.find('xmax').text)\n",
    "            ymax = int(labels_info.find('ymax').text)\n",
    "            name = member_object.find('name').text\n",
    "            \n",
    "            # Append the extracted information to the dictionary\n",
    "            labels_dict['img_path'].append(img_path)\n",
    "            labels_dict['xmin'].append(xmin)\n",
    "            labels_dict['xmax'].append(xmax)\n",
    "            labels_dict['ymin'].append(ymin)\n",
    "            labels_dict['ymax'].append(ymax)\n",
    "            labels_dict['img_w'].append(img_w)\n",
    "            labels_dict['img_h'].append(img_h)\n",
    "            labels_dict['name'].append(name)\n",
    "        \n",
    "        if not objects_found:\n",
    "            print(f\"Warning: No <object> found in {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {filename}: {e}\")\n",
    "\n",
    "# Convert the dictionary to a pandas DataFrame\n",
    "alldata = pd.DataFrame(labels_dict)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(alldata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      len(train) = 1182\n",
      "      len(val) = 169\n",
      "      len(test) = 338\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(alldata, test_size=2/10, random_state=42)\n",
    "train, val=train_test_split(train,train_size=7/8,random_state=42)\n",
    "print(f'''\n",
    "      len(train) = {len(train)}\n",
    "      len(val) = {len(val)}\n",
    "      len(test) = {len(test)}\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_split(dataframe, train_size=0.7, val_size=0.15, test_size=0.15):\n",
    "    # Identify classes with only one sample\n",
    "    class_counts = dataframe['name'].value_counts()\n",
    "    single_sample_classes = class_counts[class_counts == 1].index\n",
    "    print(single_sample_classes)\n",
    "    \n",
    "    # Separate single-sample classes from the rest\n",
    "    single_sample_states = dataframe[dataframe['name'].isin(single_sample_classes)]\n",
    "    multi_sample_states = dataframe[~dataframe['name'].isin(single_sample_classes)]\n",
    "    \n",
    "    # Perform stratified split on multi-sample classes\n",
    "    train, temp = train_test_split(\n",
    "        multi_sample_states,\n",
    "        test_size=1 - train_size,\n",
    "        stratify=multi_sample_states['name'].str[:2],  # Stratify by state\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Identify classes with only one sample in temp (for val/test split)\n",
    "    class_counts_val = temp['name'].value_counts()\n",
    "    single_sample_classes_val = class_counts_val[class_counts_val == 1].index\n",
    "    single_sample_states_val = temp[temp['name'].isin(single_sample_classes_val)]\n",
    "    multi_sample_states_val = temp[~temp['name'].isin(single_sample_classes_val)]\n",
    "    \n",
    "    # Split temp into val and test\n",
    "    val, test = train_test_split(\n",
    "        multi_sample_states_val,\n",
    "        test_size=test_size / (val_size + test_size),\n",
    "        stratify=multi_sample_states_val['name'].str[:2],  # Stratify by state\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Add single-sample states directly to the training and validation sets\n",
    "    train = pd.concat([train, single_sample_states], ignore_index=True)\n",
    "    val = pd.concat([val, single_sample_states_val], ignore_index=True)\n",
    "\n",
    "    return {\n",
    "        'train': train,\n",
    "        'val': val,\n",
    "        'test': test\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_split_folder_in_yolo_format(split_name, split_df):\n",
    "    \"\"\"\n",
    "    Creates a folder structure for a dataset split (train/val/test) in YOLO format,\n",
    "    further separating the folders by state based on the first two characters of the 'name' column.\n",
    "\n",
    "    Parameters:\n",
    "    split_name (str): The name of the split (e.g., 'train', 'val', 'test').\n",
    "    split_df (pd.DataFrame): The DataFrame containing the data for the split.\n",
    "\n",
    "    The function will create 'labels' and 'images' subdirectories under\n",
    "    'datasets/cars_license_plate/{split_name}/{state}',\n",
    "    and save the corresponding labels and images in YOLO format.\n",
    "    \"\"\"\n",
    "    base_path = os.path.join('datasets', 'cars_license_plate_new', split_name)\n",
    "    \n",
    "    # Iterate over each row in the DataFrame\n",
    "    for _, row in split_df.iterrows():\n",
    "        try:\n",
    "            # Extract state from the first two characters of the 'name' column\n",
    "            state = row['name'][:2]\n",
    "            \n",
    "            # Paths for labels and images\n",
    "            state_path = os.path.join(base_path, state)\n",
    "            labels_path = os.path.join(state_path, 'labels')\n",
    "            images_path = os.path.join(state_path, 'images')\n",
    "            \n",
    "            # Create directories for labels and images if they don't exist\n",
    "            os.makedirs(labels_path, exist_ok=True)\n",
    "            os.makedirs(images_path, exist_ok=True)\n",
    "            \n",
    "            # Extract image name and extension\n",
    "            img_name, img_extension = os.path.splitext(os.path.basename(row['img_path']))\n",
    "            \n",
    "            # Calculate YOLO format bounding box coordinates\n",
    "            x_center = (row['xmin'] + row['xmax']) / 2 / row['img_w']\n",
    "            y_center = (row['ymin'] + row['ymax']) / 2 / row['img_h']\n",
    "            width = (row['xmax'] - row['xmin']) / row['img_w']\n",
    "            height = (row['ymax'] - row['ymin']) / row['img_h']\n",
    "\n",
    "            # Save the label in YOLO format\n",
    "            label_path = os.path.join(labels_path, f'{img_name}.txt')\n",
    "            with open(label_path, 'w') as file:\n",
    "                file.write(f\"0 {x_center:.4f} {y_center:.4f} {width:.4f} {height:.4f}\\n\")\n",
    "                \n",
    "            # Check if the image file exists before copying\n",
    "            if os.path.exists(row['img_path']):\n",
    "                shutil.copy(row['img_path'], os.path.join(images_path, img_name + img_extension))\n",
    "            else:\n",
    "                print(f\"Warning: Image file not found - {row['img_path']}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing row {row['name']}: {e}\")\n",
    "    \n",
    "    print(f\"Created folders under '{base_path}' organized by state.\")\n",
    "\n",
    "# Example usage:\n",
    "# Assuming `df` is a DataFrame with columns: ['img_path', 'xmin', 'xmax', 'ymin', 'ymax', 'img_w', 'img_h', 'name']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the 'datasets' directory if it exists\n",
    "if os.path.exists('datasets'):\n",
    "    shutil.rmtree('datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['AP39TP0211', 'AP31TV7236', 'AP31BL8656', 'AP16DP7065', 'AR048395',\n",
      "       'AR152019', 'AR01J0123', 'AR118724', 'AR200692', 'AR01F2523',\n",
      "       ...\n",
      "       'WB06H2237', 'WB02A03017', 'WB02AD4162', 'WB02AM8548', 'WB70G3763',\n",
      "       'WB02X8795', 'WB06G4120', 'WB02AH4655', 'WB06J4432', 'WB02AA5580'],\n",
      "      dtype='object', name='name', length=757)\n",
      "Warning: Image file not found - data\\images\\google_images\\NL1.jpg\n",
      "Created folders under 'datasets\\cars_license_plate_new\\train' organized by state.\n",
      "Created folders under 'datasets\\cars_license_plate_new\\val' organized by state.\n",
      "Created folders under 'datasets\\cars_license_plate_new\\test' organized by state.\n"
     ]
    }
   ],
   "source": [
    "splits = stratified_split(alldata)\n",
    "for split_name, split_df in splits.items():\n",
    "    make_split_folder_in_yolo_format(split_name, split_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of folders: 37\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def count_folders_in_directory(directory_path):\n",
    "    # List all items in the directory and filter only directories\n",
    "    return len([f for f in os.listdir(directory_path) if os.path.isdir(os.path.join(directory_path, f))])\n",
    "\n",
    "# Example usage\n",
    "directory_path = r'datasets\\cars_license_plate_new\\train'  # Using raw string\n",
    "folder_count = count_folders_in_directory(directory_path)\n",
    "print(f\"Number of folders: {folder_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
